{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from numpy.random import seed\n",
    "seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from skimage.transform import resize\n",
    "from scipy.ndimage import zoom\n",
    "import numpy as np \n",
    "import os\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "import numpy as np\n",
    "from keras.losses import *\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.initializers import *\n",
    "from keras import metrics\n",
    "from keras import optimizers\n",
    "import datetime\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau, EarlyStopping\n",
    "from keras import backend as K\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import TensorBoard\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation_metrics import change_to_3D_MRI, calculate_dice, calculate_metrics, calculate_stats_3D_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('/content/drive/My Drive/Colab Notebooks/loading_data/normalized_data/X_train.npy', allow_pickle = True)\n",
    "X_val = np.load('/content/drive/My Drive/Colab Notebooks/loading_data/normalized_data/X_val.npy', allow_pickle = True)\n",
    "X_test = np.load('/content/drive/My Drive/Colab Notebooks/loading_data/normalized_data/X_test.npy', allow_pickle = True) \n",
    "y_train = np.load('/content/drive/My Drive/Colab Notebooks/loading_data/normalized_data/y_train.npy', allow_pickle = True)\n",
    "y_val = np.load('/content/drive/My Drive/Colab Notebooks/loading_data/normalized_data/y_val.npy', allow_pickle = True)\n",
    "y_test = np.load('/content/drive/My Drive/Colab Notebooks/loading_data/normalized_data/y_test.npy', allow_pickle = True)\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the lenght of the sequence that you use\n",
    "\n",
    "n = 6\n",
    "\n",
    "train_sequence = np.load('/content/drive/My Drive/Colab Notebooks/loading_data/labels/train_sequence.npy', allow_pickle = True)\n",
    "val_sequence = np.load('/content/drive/My Drive/Colab Notebooks/loading_data/labels/val_sequence.npy', allow_pickle = True)\n",
    "test_sequence =  np.load('/content/drive/My Drive/Colab Notebooks/loading_data/labels/test_sequence.npy', allow_pickle = True)\n",
    "\n",
    "print(train_sequence.shape)\n",
    "print(val_sequence.shape)\n",
    "print(test_sequence.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    coef = (2. * intersection + K.epsilon()) / (K.sum(y_true_f) + K.sum(y_pred_f) + K.epsilon())\n",
    "    return coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y_true, y_pred):\n",
    "    def dice_coef_loss(y_true, y_pred):\n",
    "        return 1-dice_coef(y_true, y_pred)\n",
    "\n",
    "    return binary_crossentropy(y_true, y_pred) + dice_coef_loss(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as tfback\n",
    "\n",
    "print(\"tf.__version__ is\", tf.__version__)\n",
    "print(\"tf.keras.__version__ is:\", tf.keras.__version__)\n",
    "\n",
    "def _get_available_gpus():\n",
    "    \"\"\"Get a list of available gpu devices (formatted as strings).\n",
    "\n",
    "    # Returns\n",
    "        A list of available GPU devices.\n",
    "    \"\"\"\n",
    "    #global _LOCAL_DEVICES\n",
    "    if tfback._LOCAL_DEVICES is None:\n",
    "        devices = tf.config.list_logical_devices()\n",
    "        tfback._LOCAL_DEVICES = [x.name for x in devices]\n",
    "    return [x for x in tfback._LOCAL_DEVICES if 'device:gpu' in x.lower()]\n",
    "\n",
    "tfback._get_available_gpus = _get_available_gpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RFCN-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try this\n",
    "\n",
    "input_size = (4,64,64)\n",
    "input_sequence = ((n,64,64,1))\n",
    "\n",
    "inputs = Input(input_size)\n",
    "conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_first')(inputs)\n",
    "conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_first')(conv1)\n",
    "batch1 = BatchNormalization()(conv1)\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2), data_format = 'channels_first')(batch1)\n",
    "\n",
    "conv2 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_first')(pool1)\n",
    "conv2 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_first')(conv2)\n",
    "batch2 = BatchNormalization()(conv2)\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2), data_format = 'channels_first')(batch2)\n",
    "\n",
    "conv3 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_first')(pool2)\n",
    "conv3 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_first')(conv3)\n",
    "batch3 = BatchNormalization()(conv3)\n",
    "pool3 = MaxPooling2D(pool_size=(2, 2), data_format = 'channels_first')(batch3)\n",
    "\n",
    "\n",
    "conv5 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_first')(pool3)\n",
    "conv5 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_first')(conv5)\n",
    "batch5 = BatchNormalization()(conv5)\n",
    "drop5 = Dropout(0.5)(batch5)\n",
    "\n",
    "up7 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_first')(UpSampling2D(size = (2,2), data_format = 'channels_first')(drop5))\n",
    "merge7 = concatenate([conv3,up7], axis = 1)\n",
    "conv7 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_first')(merge7)\n",
    "conv7 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_first')(conv7)\n",
    "batch7 = BatchNormalization()(conv7)\n",
    "\n",
    "up8 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_first')(UpSampling2D(size = (2,2), data_format = 'channels_first')(batch7))\n",
    "merge8 = concatenate([conv2,up8], axis = 1)\n",
    "conv8 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_first')(merge8)\n",
    "conv8 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_first')(conv8)\n",
    "batch8 = BatchNormalization()(conv8)\n",
    "\n",
    "up9 = Conv2D(32, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_first')(UpSampling2D(size = (2,2), data_format = 'channels_first')(batch8))\n",
    "merge9 = concatenate([conv1,up9], axis = 1)\n",
    "conv9 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_first')(merge9)\n",
    "\n",
    "input_seq = Input(input_sequence)\n",
    "convLSTM = ConvLSTM2D(64, 3, data_format='channels_last', padding='same', kernel_initializer = 'he_normal')(input_seq)\n",
    "perm1 = Permute((3,1,2))(convLSTM)\n",
    "conv4 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_first')(perm1)\n",
    "merge_seq = concatenate([conv4, conv9], axis = 1)\n",
    "conv9 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_first')(merge_seq)\n",
    "\n",
    "\n",
    "\n",
    "conv10 = Conv2D(1, 1, activation = 'sigmoid', data_format = 'channels_first')(conv9)\n",
    "\n",
    "\n",
    "\n",
    "model = Model(input = [inputs, input_seq], output = conv10)\n",
    "\n",
    "model.compile(optimizer = Adam(lr = 0.001), loss = loss , metrics = [dice_coef])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"/content/drive/My Drive/Colab Notebooks/results/result_unet_GRU\" + datetime.datetime.now().strftime('%Y%m%d')\n",
    "\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "weight_saver = ModelCheckpoint(\"/content/drive/My Drive/Colab Notebooks/results/result_unet_GRU/unet_GRU_weights.{epoch:02d}-{val_loss:.2f}.hdf5\",\n",
    "                               monitor = 'val_dice_coef', period=1,\n",
    "                               save_best_only = False, mode = 'max', save_weights_only = True)\n",
    "\n",
    "reduce_lr_on_plateau = ReduceLROnPlateau(monitor = 'val_dice_coef', factor = 0.5, patience = 5, verbose = 1, \n",
    "                                          mode = 'max', cooldown = 1, min_lr = 1e-7)\n",
    "\n",
    "early = EarlyStopping(monitor = \"val_dice_coef\", mode = \"max\", patience = 30)\n",
    "\n",
    "print(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.fit([X_train, train_adv_seq_flip], y_train, batch_size=64, epochs=300, validation_data=([X_val, val_adv_seq_flip], y_val),\n",
    "                   callbacks= [tensorboard_callback, weight_saver, reduce_lr_on_plateau, early])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RFCN-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = (4,64,64)\n",
    "input_sequence = ((n,64,64,1))\n",
    "\n",
    "inputs = Input(input_size)\n",
    "conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_first')(inputs)\n",
    "conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_first')(conv1)\n",
    "batch1 = BatchNormalization()(conv1)\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2), data_format = 'channels_first')(batch1)\n",
    "\n",
    "conv2 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_first')(pool1)\n",
    "conv2 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_first')(conv2)\n",
    "batch2 = BatchNormalization()(conv2)\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2), data_format = 'channels_first')(batch2)\n",
    "\n",
    "conv3 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_first')(pool2)\n",
    "conv3 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_first')(conv3)\n",
    "batch3 = BatchNormalization()(conv3)\n",
    "pool3 = MaxPooling2D(pool_size=(2, 2), data_format = 'channels_first')(batch3)\n",
    "\n",
    "conv5 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_first')(pool3)\n",
    "conv6 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_first')(conv5)\n",
    "\n",
    "input_seq = Input(input_sequence)\n",
    "convLSTM = ConvLSTM2D(64, 3, data_format='channels_last', padding='same', kernel_initializer = 'he_normal')(input_seq)\n",
    "perm1 = Permute((3,1,2))(convLSTM)\n",
    "conv4 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_first')(perm1)\n",
    "pool4 = MaxPool2D(pool_size=(8,8), data_format = 'channels_first')(conv4)\n",
    "merge_seq = concatenate([pool4, conv6], axis = 1)\n",
    "\n",
    "conv5 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_first')(merge_seq)\n",
    "batch5 = BatchNormalization()(conv5)\n",
    "drop5 = Dropout(0.5)(batch5)\n",
    "\n",
    "up7 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_first')(UpSampling2D(size = (2,2), data_format = 'channels_first')(drop5))\n",
    "merge7 = concatenate([conv3,up7], axis = 1)\n",
    "conv7 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_first')(merge7)\n",
    "conv7 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_first')(conv7)\n",
    "batch7 = BatchNormalization()(conv7)\n",
    "\n",
    "up8 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_first')(UpSampling2D(size = (2,2), data_format = 'channels_first')(batch7))\n",
    "merge8 = concatenate([conv2,up8], axis = 1)\n",
    "conv8 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_first')(merge8)\n",
    "conv8 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_first')(conv8)\n",
    "batch8 = BatchNormalization()(conv8)\n",
    "\n",
    "up9 = Conv2D(32, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_first')(UpSampling2D(size = (2,2), data_format = 'channels_first')(batch8))\n",
    "merge9 = concatenate([conv1,up9], axis = 1)\n",
    "conv9 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_first')(merge9)\n",
    "conv9 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_first')(conv9)\n",
    "conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_first')(conv9)\n",
    "conv10 = Conv2D(1, 1, activation = 'sigmoid', data_format = 'channels_first')(conv9)\n",
    "\n",
    "\n",
    "model = Model(input = [inputs, input_seq], output = conv10)\n",
    "\n",
    "model.compile(optimizer = Adam(lr = 0.001), loss = loss , metrics = [dice_coef, metrics.SpecificityAtSensitivity(0.5), metrics.SensitivityAtSpecificity(0.5) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('RFCN-2-n6.30-0.15.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = model.predict([X_test,test_sequence])\n",
    "test_result_3D = change_to_3D_MRI(test_result)\n",
    "y_test_3D = change_to_3D_MRI(y_test)\n",
    "test_scores = calculate_stats_3D_data(test_result_3D, y_test_3D, labels_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
