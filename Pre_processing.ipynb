{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from numpy.random import seed\n",
    "seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\flori\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\flori\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\flori\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\flori\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\flori\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\flori\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\flori\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\flori\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\flori\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\flori\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\flori\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\flori\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from skimage.transform import resize\n",
    "from scipy.ndimage import zoom\n",
    "import numpy as np \n",
    "import os\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "import numpy as np\n",
    "from keras.losses import *\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.initializers import *\n",
    "from keras import metrics\n",
    "from keras import optimizers\n",
    "import datetime\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau, EarlyStopping\n",
    "from keras import backend as K\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import TensorBoard\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation_metrics import change_to_3D_MRI, calculate_dice, calculate_metrics, calculate_stats_3D_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_3D_data(folder_path = '/content/drive/My Drive/Colab Notebooks/MICCAI_BraTS_2019_Data_Training/', img_scale = 0.266):\n",
    "  \n",
    "    tumor_type = ['HGG', 'LGG']\n",
    "\n",
    "    flair_data = []\n",
    "    t1_data = []\n",
    "    t1ce_data = []\n",
    "    t2_data = []\n",
    "    seg_data = []\n",
    "    labels = []\n",
    "\n",
    "\n",
    "    for t in tumor_type:\n",
    "        path = folder_path + t\n",
    "        for i, q in zip(os.listdir(path), tqdm(range(len(os.listdir(path)) -1))):\n",
    "            new_paths = os.path.join(path, i)\n",
    "            new_paths_list = os.listdir(new_paths)\n",
    "\n",
    "            temp_flair_data = []\n",
    "            temp_t1_data = []\n",
    "            temp_t1ce_data = []\n",
    "            temp_t2_data = []\n",
    "            temp_seg_data = []\n",
    "\n",
    "            if t == 'HGG':\n",
    "            labels.append(0)\n",
    "            if t == 'LGG':\n",
    "            labels.append(1)\n",
    "\n",
    "            for j in new_paths_list:\n",
    "            file_path = os.path.join(new_paths, j)\n",
    "            if file_path[-10:-7] == 'air':\n",
    "                temp_img = nib.load(file_path)\n",
    "                temp_img_array = np.asarray(temp_img.dataobj)\n",
    "                temp_img_array_r = np.asarray(zoom(temp_img_array, (img_scale, img_scale, img_scale), prefilter=False))\n",
    "                temp_flair_data.append(temp_img_array_r)\n",
    "\n",
    "            if file_path[-10:-7] == '_t1':\n",
    "                temp_img = nib.load(file_path)\n",
    "                temp_img_array = np.asarray(temp_img.dataobj)\n",
    "                temp_img_array_r = np.asarray(zoom(temp_img_array, (img_scale, img_scale, img_scale), prefilter=False))\n",
    "                temp_t1_data.append(temp_img_array_r)\n",
    "\n",
    "            if file_path[-10:-7] == '1ce':\n",
    "                temp_img = nib.load(file_path)\n",
    "                temp_img_array = np.asarray(temp_img.dataobj)\n",
    "                temp_img_array_r = np.asarray(zoom(temp_img_array, (img_scale, img_scale, img_scale), prefilter=False))\n",
    "                temp_t1ce_data.append(temp_img_array_r)\n",
    "\n",
    "            if file_path[-10:-7] == '_t2':\n",
    "                temp_img = nib.load(file_path)\n",
    "                temp_img_array = np.asarray(temp_img.dataobj)\n",
    "                temp_img_array_r = np.asarray(zoom(temp_img_array, (img_scale, img_scale, img_scale), prefilter=False))\n",
    "                temp_t2_data.append(temp_img_array_r)\n",
    "\n",
    "            if file_path[-10:-7] == 'seg':\n",
    "                temp_img = nib.load(file_path)\n",
    "                temp_img_array = np.asarray(temp_img.dataobj)\n",
    "                temp_img_array_r = np.asarray(zoom(temp_img_array, (img_scale, img_scale, img_scale), prefilter=False))\n",
    "                temp_seg_data.append(temp_img_array_r)\n",
    "\n",
    "            temp_flair_data_arr = np.asarray(temp_flair_data)\n",
    "            flair_data.append(temp_flair_data_arr)\n",
    "\n",
    "            temp_t1_data_arr = np.asarray(temp_t1_data)\n",
    "            t1_data.append(temp_t1_data_arr)\n",
    "\n",
    "            temp_t1ce_data_arr = np.asarray(temp_t1ce_data)\n",
    "            t1ce_data.append(temp_t1ce_data_arr)\n",
    "\n",
    "            temp_t2_data_arr = np.asarray(temp_t2_data)\n",
    "            t2_data.append(temp_t2_data_arr)\n",
    "\n",
    "            temp_seg_data_arr = np.asarray(temp_seg_data)\n",
    "            seg_data.append(temp_seg_data_arr)\n",
    "\n",
    "            print('', end='\\r')\n",
    "\n",
    "            flair_data_arr = np.asarray(flair_data)\n",
    "            t1_data_arr = np.asarray(t1_data)\n",
    "            t1ce_data_arr = np.asarray(t1ce_data)\n",
    "            t2_data_arr = np.asarray(t2_data)\n",
    "            seg_data_arr = np.asarray(seg_data)\n",
    "            labels_arr = np.asarray(labels)\n",
    "  \n",
    "  return flair_data_arr, t1_data_arr, t1ce_data_arr, t2_data_arr, seg_data_arr, labels_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flair, t1, t1ce, t2, seg, labels = load_3D_data()\n",
    "\n",
    "print(flair.shape)\n",
    "print(t1.shape)\n",
    "print(t1ce.shape)\n",
    "print(t2.shape)\n",
    "print(seg.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combine the 4 MRI types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_data(x1, x2, x3, x4):\n",
    "    data_comb = []\n",
    "    for i in range(len(x1)):\n",
    "        combined_temp = []\n",
    "        combined_temp.append(np.asarray(x1[i][0][:,:,:]))\n",
    "        combined_temp.append(np.asarray(x2[i][0][:,:,:]))\n",
    "        combined_temp.append(np.asarray(x3[i][0][:,:,:]))\n",
    "        combined_temp.append(np.asarray(x4[i][0][:,:,:]))\n",
    "        combined_temp_arr = np.asarray(combined_temp)\n",
    "        data_comb.append(combined_temp_arr)\n",
    "    return np.asarray(data_comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = combine_data(flair,t1,t1ce,t2)\n",
    "print(combined_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(data):\n",
    "    norm_data = []\n",
    "\n",
    "    for i in data:\n",
    "        temp_data = []\n",
    "        for j in i:\n",
    "            new_data = j/np.max(j)\n",
    "            temp_data.append(new_data)\n",
    "        temp_data = np.asarray(temp_data)\n",
    "        norm_data.append(temp_data)\n",
    "\n",
    "    return np.asarray(norm_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_data = normalize_data(combined_data)\n",
    "print(normalized_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data (and add labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_data(data, label):\n",
    "    labeled_data = []\n",
    "\n",
    "    for i, j in zip(label, data):\n",
    "        temp = []\n",
    "        temp.append(i)\n",
    "        temp.append(j)\n",
    "        temp_arr = np.asarray(temp)\n",
    "        labeled_data.append(temp_arr)\n",
    "    return np.asarray(labeled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_data = label_data(normalized_data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test_val, y_train, y_test_val = train_test_split(labeled_data, seg, test_size=0.30, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test_val, y_test_val, test_size=0.50, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_labels(l_data):\n",
    "    labels = []\n",
    "    data = []\n",
    "\n",
    "    for i in l_data:\n",
    "        labels.append(i[0])\n",
    "        data.append(i[1])\n",
    "\n",
    "    return np.asarray(labels), np.asarray(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_labels, X_train = split_labels(X_train)\n",
    "X_val_labels, X_val = split_labels(X_val)\n",
    "X_test_labels, X_test = split_labels(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change the data into 2D slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for train\n",
    "def change_to_2D_RGB(x):\n",
    "    rgb_data = []\n",
    "\n",
    "    for i in range(x.shape[0]):\n",
    "        for z in range(x.shape[-1]):\n",
    "            rgb_temp = []\n",
    "            for y in range(x.shape[1]):\n",
    "                rgb_temp.append(np.asarray(x[i][y][:,:,z]))\n",
    "                rgb_temp_arr = np.asarray(rgb_temp)\n",
    "        rgb_data.append(rgb_temp_arr)\n",
    "\n",
    "    rgb_data_arr = np.asarray(rgb_data)\n",
    "    return rgb_data_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for test\n",
    "def change_to_2D_slices(data_3D):\n",
    "    data_slices_2D = []\n",
    "\n",
    "    for i in range(len(data_3D)):\n",
    "        for z in range(data_3D[i].shape[-1]):\n",
    "            slice_2D = np.asarray(data_3D[i][:,:,:,z])\n",
    "            data_slices_2D.append(slice_2D)\n",
    "\n",
    "    data_slices_2D_arr = np.asarray(data_slices_2D)\n",
    "    return data_slices_2D_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_2D_bi(y_data):\n",
    "    return np.where(y_data == 0, y_data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = change_to_2D_RGB(X_train)\n",
    "X_val = change_to_2D_RGB(X_val)\n",
    "X_test = change_to_2D_RGB(X_test)\n",
    "\n",
    "y_train = change_2D_bi(change_to_2D_slices(y_train))\n",
    "y_val = change_2D_bi(change_to_2D_slices(y_val))\n",
    "y_test = change_2D_bi(change_to_2D_slices(y_test))\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the U-Net to make a sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    coef = (2. * intersection + K.epsilon()) / (K.sum(y_true_f) + K.sum(y_pred_f) + K.epsilon())\n",
    "    return coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y_true, y_pred):\n",
    "    def dice_coef_loss(y_true, y_pred):\n",
    "        return 1-dice_coef(y_true, y_pred)\n",
    "\n",
    "    return binary_crossentropy(y_true, y_pred) + dice_coef_loss(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as tfback\n",
    "\n",
    "print(\"tf.__version__ is\", tf.__version__)\n",
    "print(\"tf.keras.__version__ is:\", tf.keras.__version__)\n",
    "\n",
    "def _get_available_gpus():\n",
    "    \"\"\"Get a list of available gpu devices (formatted as strings).\n",
    "\n",
    "    # Returns\n",
    "        A list of available GPU devices.\n",
    "    \"\"\"\n",
    "    #global _LOCAL_DEVICES\n",
    "    if tfback._LOCAL_DEVICES is None:\n",
    "        devices = tf.config.list_logical_devices()\n",
    "        tfback._LOCAL_DEVICES = [x.name for x in devices]\n",
    "    return [x for x in tfback._LOCAL_DEVICES if 'device:gpu' in x.lower()]\n",
    "\n",
    "tfback._get_available_gpus = _get_available_gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\flori\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\flori\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flori\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:45: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"co...)`\n"
     ]
    }
   ],
   "source": [
    "input_size = (4,64,64)\n",
    "\n",
    "\n",
    "inputs = Input(input_size)\n",
    "conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_first')(inputs)\n",
    "conv1 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_first')(conv1)\n",
    "batch1 = BatchNormalization()(conv1)\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2), data_format = 'channels_first')(batch1)\n",
    "\n",
    "conv2 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_first')(pool1)\n",
    "conv2 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_first')(conv2)\n",
    "batch2 = BatchNormalization()(conv2)\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2), data_format = 'channels_first')(batch2)\n",
    "\n",
    "conv3 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_first')(pool2)\n",
    "conv3 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_first')(conv3)\n",
    "batch3 = BatchNormalization()(conv3)\n",
    "pool3 = MaxPooling2D(pool_size=(2, 2), data_format = 'channels_first')(batch3)\n",
    "\n",
    "conv4 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_first')(pool3)\n",
    "conv4 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_first')(conv4)\n",
    "batch4 = BatchNormalization()(conv4)\n",
    "drop4 = Dropout(0.5)(batch4)\n",
    "\n",
    "up5 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_first')(UpSampling2D(size = (2,2), data_format = 'channels_first')(drop4))\n",
    "merge5 = concatenate([conv3,up5], axis = 1)\n",
    "conv5 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_first')(merge5)\n",
    "conv5 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_first')(conv5)\n",
    "batch5 = BatchNormalization()(conv5)\n",
    "\n",
    "up6 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_first')(UpSampling2D(size = (2,2), data_format = 'channels_first')(batch5))\n",
    "merge6 = concatenate([conv2,up6], axis = 1)\n",
    "conv6 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_first')(merge6)\n",
    "conv6 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_first')(conv6)\n",
    "batch6 = BatchNormalization()(conv6)\n",
    "\n",
    "up7 = Conv2D(32, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_first')(UpSampling2D(size = (2,2), data_format = 'channels_first')(batch6))\n",
    "merge7 = concatenate([conv1,up7], axis = 1)\n",
    "conv7 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_first')(merge7)\n",
    "conv7 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_first')(conv7)\n",
    "conv8 = Conv2D(1, 1, activation = 'sigmoid', data_format = 'channels_first')(conv7)\n",
    "\n",
    "\n",
    "\n",
    "model = Model(input = inputs, output = conv8)\n",
    "\n",
    "model.compile(optimizer = Adam(lr = 0.001), loss = loss , metrics = [dice_coef])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U-net test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('unet_weights.35-0.15.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = model.predict([X_test,test_sequence])\n",
    "test_result_3D = change_to_3D_MRI(test_result)\n",
    "y_test_3D = change_to_3D_MRI(y_test)\n",
    "test_scores = calculate_stats_3D_data(test_result_3D, y_test_3D, labels_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the best model loaded from the U-Net\n",
    "model.load_weights('unet_weights.35-0.15.hdf5')\n",
    "\n",
    "# n = the length of the sequence used in the RFCN\n",
    "n = 6\n",
    "\n",
    "def create_sequence(X_data, n=n, y_data = y_train, y_true = 'N'):\n",
    "\n",
    "    test_masks = model.predict(X_data)\n",
    "    test_masks = np.round(test_masks)\n",
    "\n",
    "    r = np.arange(41)\n",
    "    x =  np.tile(r, int(len(test_masks)/41))\n",
    "    y = np.arange(len(test_masks))\n",
    "\n",
    "    test_sequence = []\n",
    "\n",
    "    for i, j in zip(x, y):\n",
    "        if i == 0:\n",
    "            base = np.zeros((n,64,64))     \n",
    "            base[0] = 2\n",
    "            test_sequence.append(base)\n",
    "\n",
    "        else:\n",
    "            if y_true == 'Y':\n",
    "                temp = y_data[(j-1)][:,:,:] \n",
    "                temp = np.where(temp == 1, 10, 5)\n",
    "                base_2 = test_sequence[j-1].copy()\n",
    "                base_plus = np.vstack((temp, base_2))[:n]\n",
    "                test_sequence.append(base_plus)\n",
    "\n",
    "            else:\n",
    "                temp = test_masks[(j-1)][:,:,:] \n",
    "                temp = np.where(temp == 1, 10, 5)\n",
    "                base_2 = test_sequence[j-1].copy()\n",
    "                base_plus = np.vstack((temp, base_2))[:n]\n",
    "                test_sequence.append(base_plus)\n",
    "\n",
    "    seq_arr = np.asarray(test_sequence)\n",
    "\n",
    "    flipped_sequence = []\n",
    "    for i in seq_arr:\n",
    "        flipped = np.flip(i, axis = 0)\n",
    "        flipped_sequence.append(flipped)\n",
    "\n",
    "    return np.expand_dims(np.asarray(flipped_sequence), axis = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequence = create_sequence(X_train, y_data = y_train, y_true = 'N')\n",
    "val_sequence = create_sequence(X_val, y_data = y_val, y_true = 'N')\n",
    "test_sequence = create_sequence(X_test, y_data = y_test, y_true = 'N')\n",
    "\n",
    "print(train_sequence.shape)\n",
    "print(val_sequence.shape)\n",
    "print(test_sequence.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test if the sequence is correct\n",
    "plt.imshow(y_train[16][0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_sequence[17].reshape((n,64,64))[(n-1)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
